{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T04:41:42.455083Z",
     "start_time": "2024-10-01T04:41:39.895914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.07192861, -0.07396872,  0.04011194, ...,  0.0279322 ,\n       -0.020931  ,  0.02410343], dtype=float32)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bio_embeddings.embed import ProtTransBertBFDEmbedder\n",
    "embedder = ProtTransBertBFDEmbedder()\n",
    "embedding = embedder.embed(\"SEQVENCE\")\n",
    "# per-protein embeddings\n",
    "embedder.reduce_per_protein(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.0467555 , -0.07190941, -0.0314257 , ...,  0.01172287,\n         0.01092037,  0.04518341],\n       [ 0.10794733, -0.09779151,  0.09046077, ...,  0.11499642,\n         0.02417662, -0.04991413],\n       [ 0.09692698, -0.07898042,  0.02561175, ..., -0.05614557,\n        -0.14321952,  0.06902924],\n       ...,\n       [-0.04686003, -0.10101403, -0.02419611, ...,  0.03296087,\n         0.00505309,  0.14111729],\n       [ 0.05784511, -0.08158087,  0.11660787, ...,  0.01369378,\n        -0.1004184 ,  0.07407311],\n       [ 0.09855117, -0.07230176,  0.09183894, ...,  0.05356697,\n        -0.00147113, -0.06082158]], dtype=float32)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T04:39:56.985940Z",
     "start_time": "2024-10-01T04:39:56.963277Z"
    }
   },
   "id": "10f46108f4c80f42",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/Users/cgu3/anaconda3/envs/mpi/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from bio_embeddings.embed import ProtTransT5XLU50Embedder\n",
    "embedder =ProtTransT5XLU50Embedder(model_directory='/Users/cgu3/embedding_model/prottrans_t5_xl_u50')\n",
    "embedding = embedder.embed(\"SEQVENCE\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T15:05:38.492936Z",
     "start_time": "2024-10-01T15:05:15.987906Z"
    }
   },
   "id": "b97d3b6ce12e7d20",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.05349896, -0.27111423, -0.20694031, ...,  0.03310625,\n         0.1262396 , -0.00272362],\n       [ 0.29572213, -0.21138924, -0.04381543, ...,  0.07277953,\n        -0.00139775,  0.07307985],\n       [ 0.18441643, -0.16697167, -0.3717018 , ...,  0.11060952,\n         0.15383308, -0.04541315],\n       ...,\n       [ 0.01677627, -0.08012161, -0.26621073, ..., -0.01993215,\n         0.13406374, -0.06205409],\n       [-0.00301866, -0.12795064,  0.1355054 , ..., -0.00137251,\n         0.18704237, -0.15348405],\n       [ 0.14121874, -0.0552098 ,  0.16018982, ...,  0.03688513,\n        -0.02131686, -0.02979411]], dtype=float32)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T15:06:03.927197Z",
     "start_time": "2024-10-01T15:06:03.922769Z"
    }
   },
   "id": "4b22ccaa48360e85",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "56af264710064d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
